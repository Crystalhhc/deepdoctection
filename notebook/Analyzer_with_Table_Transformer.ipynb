{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8787164b-1bf9-4f40-a6f5-5b0c110f1ef2",
   "metadata": {},
   "source": [
    "# Analyzer configuration for running Table Transformer\n",
    "\n",
    "\n",
    "In this notebook, we demonstrate how the [Table Transformer](https://github.com/microsoft/table-transformer) models can be utilized for table detection and table segmentation by adjusting the analyzer's default configuration. \n",
    "\n",
    "Additionally, we illustrate that modifying downstream parameters might be beneficial as well. We start from the default configuration and improve the quality of page parsing only by changing some processing parameters. The chosen configurations in this notebook may not be optimal, and we recommend continuing experimentation with the parameters, especially if fine-tuning models is not an option.\n",
    "\n",
    "## General configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e5e1f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepdoctection[pt]\n",
      "  Using cached deepdoctection-0.36-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: catalogue==2.0.10 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (2.0.10)\n",
      "Requirement already satisfied: huggingface_hub<0.26,>=0.12.0 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (0.17.2)\n",
      "Requirement already satisfied: importlib-metadata>=5.0.0 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (7.1.0)\n",
      "Requirement already satisfied: jsonlines==3.1.0 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (3.1.0)\n",
      "Collecting lazy-imports==0.3.1 (from deepdoctection[pt])\n",
      "  Using cached lazy_imports-0.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: mock==4.0.3 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (4.0.3)\n",
      "Requirement already satisfied: networkx>=2.7.1 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (2.7.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (21.3)\n",
      "Requirement already satisfied: Pillow>=10.0.0 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (10.0.1)\n",
      "Requirement already satisfied: pypdf>=3.16.0 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (3.17.3)\n",
      "Collecting pypdfium2>=4.30.0 (from deepdoctection[pt])\n",
      "  Using cached pypdfium2-4.30.0-py3-none-macosx_10_13_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (6.0.1)\n",
      "Requirement already satisfied: pyzmq>=16 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (24.0.1)\n",
      "Collecting scipy>=1.13.1 (from deepdoctection[pt])\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: termcolor>=1.1 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (2.0.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (0.8.10)\n",
      "Requirement already satisfied: tqdm==4.64.0 in /Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages (from deepdoctection[pt]) (4.64.0)\n",
      "Collecting timm>=0.9.16 (from deepdoctection[pt])\n",
      "  Using cached timm-1.0.11-py3-none-any.whl.metadata (48 kB)\n",
      "Collecting transformers>=4.36.0 (from deepdoctection[pt])\n",
      "  Using cached transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting accelerate>=0.29.1 (from deepdoctection[pt])\n",
      "  Using cached accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting python-doctr==0.8.1 (from deepdoctection[pt])\n",
      "  Using cached python_doctr-0.8.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting boto3==1.34.102 (from deepdoctection[pt])\n",
      "  Using cached boto3-1.34.102-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pdfplumber>=0.11.0 (from deepdoctection[pt])\n",
      "  Using cached pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting fasttext==0.9.2 (from deepdoctection[pt])\n",
      "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[25 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /Users/chenhsihu/eval/deepdoctection/.venv/bin/python: No module named pip\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 38, in __init__\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'pybind11'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m During handling of the above exception, another exception occurred:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/chenhsihu/eval/deepdoctection/.venv/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/y2/0flrd2290_5036hw72912kxh0000gp/T/pip-build-env-2nj6gvot/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/y2/0flrd2290_5036hw72912kxh0000gp/T/pip-build-env-2nj6gvot/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 304, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/y2/0flrd2290_5036hw72912kxh0000gp/T/pip-build-env-2nj6gvot/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 522, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/y2/0flrd2290_5036hw72912kxh0000gp/T/pip-build-env-2nj6gvot/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 320, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 72, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 41, in __init__\n",
      "  \u001b[31m   \u001b[0m RuntimeError: pybind11 install failed.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install 'deepdoctection[pt]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3b6d3cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepdoctection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdeepdoctection\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(dd\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepdoctection'"
     ]
    }
   ],
   "source": [
    "import deepdoctection as dd\n",
    "print(dd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64b84c9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'notebook'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnotebook\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(notebook\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'notebook'"
     ]
    }
   ],
   "source": [
    "import notebook\n",
    "print(notebook.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d885eb5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Users/chenhsihu'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Using os.path\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "\n",
    "# Or using pathlib (Python 3.5+)\n",
    "home_dir = str(Path.home())\n",
    "print({home_dir})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "254231ad-933e-4b66-b98b-b655a4378d8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepdoctection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE_DD_PILLOW\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE_DD_OPENCV\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdeepdoctection\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepdoctection'"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"USE_DD_PILLOW\"]=\"True\"\n",
    "os.environ[\"USE_DD_OPENCV\"]=\"False\"\n",
    "\n",
    "import deepdoctection as dd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880fa51c-2748-4fd0-a843-56a60639c7e1",
   "metadata": {},
   "source": [
    "The first configuration replaces the default layout and segmentation models with the registered table transformer models. The values need to be the equal to the model names in the `ModelCatalog`. You can find all registered model with `ModelCatalog.get_profile_list()`.\n",
    "\n",
    "The table recognition model identifies tables again from cropped table regions. This is irrelevant for processing and actually leads to errors. For this reason, category `table` must be filtered out.\n",
    "\n",
    "```yaml\n",
    "PT:\n",
    "   LAYOUT:\n",
    "      WEIGHTS: microsoft/table-transformer-detection/pytorch_model.bin\n",
    "   ITEM:\n",
    "      WEIGHTS: microsoft/table-transformer-structure-recognition/pytorch_model.bin\n",
    "      FILTER:\n",
    "         - table\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d943619-effa-48f8-b5dc-2cf3d71532b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241m.\u001b[39manalyze(path\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mreset_state()\n\u001b[1;32m      3\u001b[0m dp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(df))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'analyzer' is not defined"
     ]
    }
   ],
   "source": [
    "df = analyzer.analyze(path=path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "\n",
    "np_image = dp.viz()\n",
    "\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dae428-95ad-4867-aaf7-49394410d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.tables[0].csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ba820-9c56-4d2f-a5cd-855c6efae384",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.tables[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25452626-f87f-44d2-b0c0-54ed0774a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ab182c-e3db-4f55-a83f-5ee6f7f5a56d",
   "metadata": {},
   "source": [
    "Okay, table detection doesn't work at all. Besides that, we see that no text is recognized outside of the table. To suppress this poor table region prediction, we are increasing the filter confidence score to 0.4. We cannot change this directly in the `analyzer` configuration. \n",
    "\n",
    "The surrounding text is not displayed because the configuration only outputs the text within a layout segment. In this case, these are only tables. If we set `TEXT_ORDERING.INCLUDE_RESIDUAL_TEXT_CONTAINER=True`, line layout segments will be generated for all words, and all all line segments will be taken into account when generating narrative text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a79d79-c391-45d1-a670-09383c39802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=\"/path/to/dir/sample/2312.13560.pdf\" # Use the PDF in the sample folder\n",
    "path = \"/home/janis/Documents/Repos/notebooks/sample/2312.13560.pdf\"\n",
    "    \n",
    "analyzer =dd.get_dd_analyzer(config_overwrite=\n",
    "   [\"PT.LAYOUT.WEIGHTS=microsoft/table-transformer-detection/pytorch_model.bin\",\n",
    "    \"PT.ITEM.WEIGHTS=microsoft/table-transformer-structure-recognition/pytorch_model.bin\",\n",
    "    \"PT.ITEM.FILTER=['table']\",\n",
    "    \"OCR.USE_DOCTR=True\",\n",
    "    \"OCR.USE_TESSERACT=False\",\n",
    "    \"TEXT_ORDERING.INCLUDE_RESIDUAL_TEXT_CONTAINER=True\",\n",
    "                        ])\n",
    "\n",
    "analyzer.pipe_component_list[0].predictor.config.threshold = 0.4  # default threshold is at 0.1\n",
    "\n",
    "df = analyzer.analyze(path=path)\n",
    "df.reset_state()\n",
    "dp = next(iter(df))\n",
    "\n",
    "np_image = dp.viz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccb997-12a5-469c-b47f-c332f5dc445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4106d55-52cb-4b5d-b510-4eaa02484937",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee4939d-71ab-4e13-8f50-2aabe7eb48f1",
   "metadata": {},
   "source": [
    "The result is not much better. Although we are able to retrieve text outside tables, we observe that the text lines span across multiple columns. This leads to a disastrous outcome in terms of reading order. \n",
    "\n",
    "The construction of text lines is done heuristically. In particular, it is determined when adjacent words belong to the same text line and when text lines need to be separated, even if they are at the same horizontal level. \n",
    "\n",
    "By reducing the value of `TEXT_ORDERING.PARAGRAPH_BREAK`, we can achieve the splitting of text lines as soon as the word boxes exceed a minimum distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34845a02-c126-471f-bb85-5a68f97dc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=\"/path/to/dir/sample/2312.13560.pdf\" # Use the PDF in the sample folder\n",
    "path = \"/home/janis/Documents/Repos/notebooks/sample/2312.13560.pdf\"\n",
    "    \n",
    "analyzer =dd.get_dd_analyzer(config_overwrite=\n",
    "   [\"PT.LAYOUT.WEIGHTS=microsoft/table-transformer-detection/pytorch_model.bin\",\n",
    "    \"PT.ITEM.WEIGHTS=microsoft/table-transformer-structure-recognition/pytorch_model.bin\",\n",
    "    \"PT.ITEM.FILTER=['table']\",\n",
    "    \"OCR.USE_DOCTR=True\",\n",
    "    \"OCR.USE_TESSERACT=False\",\n",
    "    \"TEXT_ORDERING.INCLUDE_RESIDUAL_TEXT_CONTAINER=True\",\n",
    "    \"TEXT_ORDERING.PARAGRAPH_BREAK=0.01\",  # default value is at 0.035 which might be too large\n",
    "                        ])\n",
    "\n",
    "analyzer.pipe_component_list[0].predictor.config.threshold = 0.4\n",
    "\n",
    "df = analyzer.analyze(path=path)\n",
    "df.reset_state()\n",
    "df_iter = iter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25889858-b890-4449-bd77-9cb912f0ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = next(df_iter)\n",
    "np_image = dp.viz()\n",
    "\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df44d2-939d-41de-a031-fb7baf1b660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73336b4-9daa-49e2-b85f-245c2220c05a",
   "metadata": {},
   "source": [
    "Okay, this page looks good now. Let's continue scrolling through the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c6ac8a-6c34-4774-8f86-5be99dde45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = next(df_iter)\n",
    "np_image = dp.viz()\n",
    "\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(np_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10abd126-6c58-456e-82e5-25114a5c66e6",
   "metadata": {},
   "source": [
    "Once again, we observe a false positive, this time with an even higher confidence threshold. We are not going to increase the threshold, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e1dde-7868-43dd-b1c0-72e6fca331d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.tables[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf688f-6d1f-4825-a58e-a37b71f2ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542baf18-9f1d-440d-a75a-9f65424e40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = next(df_iter)\n",
    "np_image = dp.viz()\n",
    "\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dacd75-555c-43b8-8059-ec7e3ba5c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = next(df_iter)\n",
    "np_image = dp.viz()\n",
    "\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(np_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca9b6b1-99ef-46a9-877e-63e0041870a9",
   "metadata": {},
   "source": [
    "The results now look quite decent, and the segmentation is also yielding usable outcomes. However, as noted in many instances, it should be acknowledged that the models may produce much weaker results on other types of documents.\n",
    "\n",
    "## Table segmentation\n",
    "\n",
    "We will now take a look at another example, focusing on optimizations in table segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b019458-9820-435b-9ca5-a37fa95fb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=\"/path/to/dir/sample/finance\" # Use the PDF in the sample folder\n",
    "path = \"/home/janis/Documents/Repos/notebooks/sample/finance\"\n",
    "    \n",
    "analyzer =dd.get_dd_analyzer(config_overwrite=\n",
    "   [\"PT.LAYOUT.WEIGHTS=microsoft/table-transformer-detection/pytorch_model.bin\",\n",
    "    \"PT.ITEM.WEIGHTS=microsoft/table-transformer-structure-recognition/pytorch_model.bin\",\n",
    "    \"PT.ITEM.FILTER=['table']\",\n",
    "    \"OCR.USE_DOCTR=True\",\n",
    "    \"OCR.USE_TESSERACT=False\",\n",
    "    \"TEXT_ORDERING.INCLUDE_RESIDUAL_TEXT_CONTAINER=True\",\n",
    "    \"TEXT_ORDERING.PARAGRAPH_BREAK=0.01\",\n",
    "                        ])\n",
    "\n",
    "analyzer.pipe_component_list[0].predictor.config.threshold = 0.4  # default threshold is at 0.1\n",
    "\n",
    "df = analyzer.analyze(path=path)\n",
    "df.reset_state()\n",
    "df_iter = iter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51203ae5-003f-412d-8c55-36c7e55e6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = next(df_iter)\n",
    "np_image = dp.viz()\n",
    "\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b26ab3-d692-4dd8-bf6a-93ae2ef23f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(dp.tables[0].html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea96c64-fd15-43a6-b5b8-58425c883b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(dp.tables[1].html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4397f-2718-4d73-9286-57521317ea43",
   "metadata": {},
   "source": [
    "The table segmentation incorporates various cell types identified by the segmentation model and processes them. Unfortunately, the detection of, for example, spanning cells does not work particularly well. This can be observed from the last sample where the model identifies at first column contains a spanning cell. We want to deactivate this feature. To do this, we need to filter out all cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a4ea4-7d55-43e9-a64d-390f39631725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=\"/path/to/dir/sample/finance\" # Use the PDF in the sample folder\n",
    "path = \"/home/janis/Documents/Repos/notebooks/sample/finance\"\n",
    "    \n",
    "analyzer =dd.get_dd_analyzer(config_overwrite=\n",
    "   [\"PT.LAYOUT.WEIGHTS=microsoft/table-transformer-detection/pytorch_model.bin\",\n",
    "    \"PT.ITEM.WEIGHTS=microsoft/table-transformer-structure-recognition/pytorch_model.bin\",\n",
    "    \"PT.ITEM.FILTER=['table','column_header','projected_row_header','spanning']\",\n",
    "    \"OCR.USE_DOCTR=True\",\n",
    "    \"OCR.USE_TESSERACT=False\",\n",
    "    \"TEXT_ORDERING.INCLUDE_RESIDUAL_TEXT_CONTAINER=True\",\n",
    "    \"TEXT_ORDERING.PARAGRAPH_BREAK=0.01\",\n",
    "                        ])\n",
    "\n",
    "analyzer.pipe_component_list[0].predictor.config.threshold = 0.4\n",
    "\n",
    "df = analyzer.analyze(path=path)\n",
    "df.reset_state()\n",
    "df_iter = iter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9ec19-6494-42e3-bc14-e1eba4f77c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = next(df_iter)\n",
    "np_image = dp.viz()\n",
    "\n",
    "plt.figure(figsize = (25,17))\n",
    "plt.axis('off')\n",
    "plt.imshow(np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b498e-1220-4279-a1e7-51fc9f789d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(dp.tables[0].html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c0250-1943-4bfa-86bb-198ec68cf050",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(dp.tables[1].html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a746692-a4f5-45f3-89c8-65bb5b150c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(dp.tables[2].html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f107773-40d5-439d-86ad-bb80d52c9671",
   "metadata": {},
   "source": [
    "As already mentiond, all text that is not part of table cells will be pushed into the narrative text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f2582-fd64-41d8-a741-152aedc236be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8cdbfa-6365-46b1-874a-e94e31c1204e",
   "metadata": {},
   "source": [
    "There are additional configuration parameters that can improve segmentation. These include, for example, `SEGMENTATION.THRESHOLD_ROWS`, `SEGMENTATION.THRESHOLD_COLS`, `SEGMENTATION.REMOVE_IOU_THRESHOLD_ROWS`, and `SEGMENTATION.REMOVE_IOU_THRESHOLD_COLS`. To observe the effects, we recommend experimenting with these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eebb3d-2cf6-4590-907a-5277d4ff2fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
